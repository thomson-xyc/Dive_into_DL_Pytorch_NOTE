{"cells":[{"metadata":{"cell_type":"code","id":"311161B6D22145348C73ED30A3501049","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 机器翻译\n机器翻译的主要特征是：输出是单词序列而不是单个单词。 输出序列的长度可能与源序列的长度不同。"},{"metadata":{"id":"86A75BBDA125408C822B21120A8A54EE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import os\nos.listdir('/home/kesci/input/')\nimport sys\nsys.path.append('/home/kesci/input/d2l9528/')\nimport collections\nimport d2l\nimport zipfile\nfrom d2l.data.base import Vocab\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils import data\nfrom torch import optim","execution_count":1},{"metadata":{"id":"7B840D4662014FCF9ECA472288875F83","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 数据预处理\nwith open('/home/kesci/input/fraeng6506/fra.txt', 'r') as f:\n      raw_text = f.read()\nprint(raw_text[0:1000])\n\ndef preprocess_raw(text):\n    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n    out = ''\n    for i, char in enumerate(text.lower()):\n        if char in (',', '!', '.') and i > 0 and text[i-1] != ' ':\n            out += ' '\n        out += char\n    return out\n\ntext = preprocess_raw(raw_text)\nprint(text[0:1000])","execution_count":2},{"metadata":{"id":"463D6B44ECA243A1B131540510B9637D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 分词\nnum_examples = 50000\nsource, target = [], []\nfor i, line in enumerate(text.split('\\n')):\n    if i > num_examples:\n        break\n    parts = line.split('\\t')\n    if len(parts) >= 2:\n        source.append(parts[0].split(' '))\n        target.append(parts[1].split(' '))\n        \nprint(source[0:3], target[0:3])\n# 图表展示\nd2l.set_figsize()\nd2l.plt.hist([[len(l) for l in source], [len(l) for l in target]],label=['source', 'target'])\nd2l.plt.legend(loc='upper right')","execution_count":3},{"metadata":{"id":"8C3519AD322A40658741801056D3FF88","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 建立词典\ndef build_vocab(tokens):\n    tokens = [token for line in tokens for token in line]\n    return d2l.data.base.Vocab(tokens, min_freq=3, use_special_tokens=True)\n\nsrc_vocab = build_vocab(source)\nlen(src_vocab)\n\n# 载入数据集\ndef pad(line, max_len, padding_token):\n    if len(line) > max_len:\n        return line[:max_len]\n    return line + [padding_token] * (max_len - len(line))\npad(src_vocab[source[0]], 10, src_vocab.pad)\n\ndef load_data_nmt(batch_size, max_len): # This function is saved in d2l.\n    src_vocab, tgt_vocab = build_vocab(source), build_vocab(target)\n    src_array, src_valid_len = build_array(source, src_vocab, max_len, True)\n    tgt_array, tgt_valid_len = build_array(target, tgt_vocab, max_len, False)\n    train_data = data.TensorDataset(src_array, src_valid_len, tgt_array, tgt_valid_len)\n    train_iter = data.DataLoader(train_data, batch_size, shuffle=True)\n    return src_vocab, tgt_vocab, train_iter\n\nsrc_vocab, tgt_vocab, train_iter = load_data_nmt(batch_size=2, max_len=8)\nfor X, X_valid_len, Y, Y_valid_len, in train_iter:\n    print('X =', X.type(torch.int32), '\\nValid lengths for X =', X_valid_len,\n        '\\nY =', Y.type(torch.int32), '\\nValid lengths for Y =', Y_valid_len)\n    break","execution_count":4},{"metadata":{"id":"663CBABB7D8F46E78CCB6698C8ADBF7D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# encoder：输入到隐藏状态 \nclass Encoder(nn.Module):\n    def __init__(self, **kwargs):\n        super(Encoder, self).__init__(**kwargs)\n\n    def forward(self, X, *args):\n        raise NotImplementedError\n\n# decoder：隐藏状态到输出\nclass Decoder(nn.Module):\n    def __init__(self, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n\n    def init_state(self, enc_outputs, *args):\n        raise NotImplementedError\n\n    def forward(self, X, state):\n        raise NotImplementedError\n\nclass EncoderDecoder(nn.Module):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(EncoderDecoder, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, enc_X, dec_X, *args):\n        enc_outputs = self.encoder(enc_X, *args)\n        dec_state = self.decoder.init_state(enc_outputs, *args)\n        return self.decoder(dec_X, dec_state)","execution_count":5},{"metadata":{"id":"41A7886F33504961858777DA0E7CBFD6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"因为机器翻译的输入与输出个数可能并不相等，比如英文“I am Chinese”有三个单词，但翻译成汉语“我是中国人”有五个汉字，这时候就需要编码(encoding)和解码(decoding)机制。\n### Encoder"},{"metadata":{"id":"324852E76C344D9C855E01BC26067498","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"class Seq2SeqEncoder(d2l.Encoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqEncoder, self).__init__(**kwargs)\n        self.num_hiddens=num_hiddens\n        self.num_layers=num_layers\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)\n   \n    def begin_state(self, batch_size, device):\n        return [torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device),\n                torch.zeros(size=(self.num_layers, batch_size, self.num_hiddens),  device=device)]\n    def forward(self, X, *args):\n        X = self.embedding(X) # X shape: (batch_size, seq_len, embed_size)\n        X = X.transpose(0, 1)  # RNN needs first axes to be time\n        # state = self.begin_state(X.shape[1], device=X.device)\n        out, state = self.rnn(X)\n        # The shape of out is (seq_len, batch_size, num_hiddens).\n        # state contains the hidden state and the memory cell\n        # of the last time step, the shape is (num_layers, batch_size, num_hiddens)\n        return out, state\n        \nencoder = Seq2SeqEncoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2)\nX = torch.zeros((4, 7),dtype=torch.long)\noutput, state = encoder(X)\noutput.shape, len(state), state[0].shape, state[1].shape","execution_count":6},{"metadata":{"id":"83D5026592D746F4BA7F6C4149BB7F0A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"### Decoder"},{"metadata":{"id":"DE9E82EFDDB34DB591A75169CDC48519","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"class Seq2SeqDecoder(d2l.Decoder):\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqDecoder, self).__init__(**kwargs)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.LSTM(embed_size,num_hiddens, num_layers, dropout=dropout)\n        self.dense = nn.Linear(num_hiddens,vocab_size)\n\n    def init_state(self, enc_outputs, *args):\n        return enc_outputs[1]\n\n    def forward(self, X, state):\n        X = self.embedding(X).transpose(0, 1)\n        out, state = self.rnn(X, state)\n        # Make the batch to be the first dimension to simplify loss computation.\n        out = self.dense(out).transpose(0, 1)\n        return out, state\n\ndecoder = Seq2SeqDecoder(vocab_size=10, embed_size=8,num_hiddens=16, num_layers=2)\nstate = decoder.init_state(encoder(X))\nout, state = decoder(X, state)\nout.shape, len(state), state[0].shape, state[1].shape","execution_count":7},{"metadata":{"id":"EAEEFE51A9E1476F88643B80865674D3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 损失函数\ndef SequenceMask(X, X_len,value=0):\n    maxlen = X.size(1)\n    mask = torch.arange(maxlen)[None, :].to(X_len.device) < X_len[:, None]   \n    X[~mask]=value\n    return X\n\nclass MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n    # pred shape: (batch_size, seq_len, vocab_size)\n    # label shape: (batch_size, seq_len)\n    # valid_length shape: (batch_size, )\n    def forward(self, pred, label, valid_length):\n        # the sample weights shape should be (batch_size, seq_len)\n        weights = torch.ones_like(label)\n        weights = SequenceMask(weights, valid_length).float()\n        self.reduction='none'\n        output=super(MaskedSoftmaxCELoss, self).forward(pred.transpose(1,2), label)\n        return (output*weights).mean(dim=1)","execution_count":8},{"metadata":{"id":"B57108A1CC0E4C438EB21E0791348ED7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 训练模型\ndef train_ch7(model, data_iter, lr, num_epochs, device):  # Saved in d2l\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    loss = MaskedSoftmaxCELoss()\n    tic = time.time()\n    for epoch in range(1, num_epochs+1):\n        l_sum, num_tokens_sum = 0.0, 0.0\n        for batch in data_iter:\n            optimizer.zero_grad()\n            X, X_vlen, Y, Y_vlen = [x.to(device) for x in batch]\n            Y_input, Y_label, Y_vlen = Y[:,:-1], Y[:,1:], Y_vlen-1\n            \n            Y_hat, _ = model(X, Y_input, X_vlen, Y_vlen)\n            l = loss(Y_hat, Y_label, Y_vlen).sum()\n            l.backward()\n\n            with torch.no_grad():\n                d2l.grad_clipping_nn(model, 5, device)\n            num_tokens = Y_vlen.sum().item()\n            optimizer.step()\n            l_sum += l.sum().item()\n            num_tokens_sum += num_tokens\n        if epoch % 50 == 0:\n            print(\"epoch {0:4d},loss {1:.3f}, time {2:.1f} sec\".format( \n                  epoch, (l_sum/num_tokens_sum), time.time()-tic))\n            tic = time.time()\n            \nembed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\nbatch_size, num_examples, max_len = 64, 1e3, 10\nlr, num_epochs, ctx = 0.005, 300, d2l.try_gpu()\nsrc_vocab, tgt_vocab, train_iter = d2l.load_data_nmt(\n    batch_size, max_len,num_examples)\nencoder = Seq2SeqEncoder(\n    len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\ndecoder = Seq2SeqDecoder(\n    len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\nmodel = d2l.EncoderDecoder(encoder, decoder)\ntrain_ch7(model, train_iter, lr, num_epochs, ctx)","execution_count":9},{"metadata":{"id":"0E62159927E141598A425D9529CDB0D4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 测试模型\ndef translate_ch7(model, src_sentence, src_vocab, tgt_vocab, max_len, device):\n    src_tokens = src_vocab[src_sentence.lower().split(' ')]\n    src_len = len(src_tokens)\n    if src_len < max_len:\n        src_tokens += [src_vocab.pad] * (max_len - src_len)\n    enc_X = torch.tensor(src_tokens, device=device)\n    enc_valid_length = torch.tensor([src_len], device=device)\n    # use expand_dim to add the batch_size dimension.\n    enc_outputs = model.encoder(enc_X.unsqueeze(dim=0), enc_valid_length)\n    dec_state = model.decoder.init_state(enc_outputs, enc_valid_length)\n    dec_X = torch.tensor([tgt_vocab.bos], device=device).unsqueeze(dim=0)\n    predict_tokens = []\n    for _ in range(max_len):\n        Y, dec_state = model.decoder(dec_X, dec_state)\n        # The token with highest score is used as the next time step input.\n        dec_X = Y.argmax(dim=2)\n        py = dec_X.squeeze(dim=0).int().item()\n        if py == tgt_vocab.eos:\n            break\n        predict_tokens.append(py)\n    return ' '.join(tgt_vocab.to_tokens(predict_tokens))\n\nfor sentence in ['Go .', 'Wow !', \"I'm OK .\", 'I won !']:\n    print(sentence + ' => ' + translate_ch7(\n        model, sentence, src_vocab, tgt_vocab, max_len, ctx))","execution_count":10},{"metadata":{"id":"5E530F700D3C40CF836B57C418ED80C6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}