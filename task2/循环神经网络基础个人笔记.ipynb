{"cells":[{"metadata":{"cell_type":"code","id":"CC68161448944EBA89A77093E1F33157","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 循环神经网络基础\n循环神经网络（RNN）与一般的神经网络不同，普通神经网络中每一层的结果只与上一层传入的值相关，而循环神经网络的各层不止基于上一层网络，还需要保留前面一些网络层的记忆。直观的比较一下多层感知机与RNN：\n多层感知机：\n![Image Name](https://cdn.kesci.com/upload/image/q5othz8lfr.jpg?imageView2/0/w/960/h/960)\n循环神经网络：\n![Image Name](https://cdn.kesci.com/upload/image/q5othfmq5s.PNG?imageView2/0/w/960/h/960)"},{"metadata":{"id":"EDCB2DDF5B524D2D88F88D2AEAF85973","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"这次学习中的问题：这次rnn学习中都是公式描述，形象描述较少，不怎么理解[手动捂脸]"},{"metadata":{"id":"9EC81A74512F4F71A1D74FEBF1BC338F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## pytorch实现"},{"metadata":{"id":"E7FB93F4BB434C95A52D5AB90F9E4432","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import torch\nimport torch.nn as nn\nimport time\nimport math\nimport torchtext\nimport sys\nsys.path.append(\"/home/kesci/input\")\nimport d2l_jay9460 as d2l\n(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":7},{"metadata":{"id":"C35DD86B92CC43398D0AA54022BF4C23","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"标注问题：d2l_jay9460无法导入，‘缺少torchtext模块’"},{"metadata":{"id":"E02825D77ED1450D87E6ABBF6E903A07","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 构造rnn实例\nrnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)\nnum_steps, batch_size = 35, 2\nX = torch.rand(num_steps, batch_size, vocab_size)\nstate = None\nY, state_new = rnn_layer(X, state)\nprint(Y.shape, state_new.shape)\n\n\n# 定义一个完整的基于循环神经网络的语言模型\nclass RNNModel(nn.Module):\n    def __init__(self, rnn_layer, vocab_size):\n        super(RNNModel, self).__init__()\n        self.rnn = rnn_layer\n        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n        self.vocab_size = vocab_size\n        self.dense = nn.Linear(self.hidden_size, vocab_size)\n\n    def forward(self, inputs, state):\n        # inputs.shape: (batch_size, num_steps)\n        X = to_onehot(inputs, vocab_size)\n        X = torch.stack(X)  # X.shape: (num_steps, batch_size, vocab_size)\n        hiddens, state = self.rnn(X, state)\n        hiddens = hiddens.view(-1, hiddens.shape[-1])  # hiddens.shape: (num_steps * batch_size, hidden_size)\n        output = self.dense(hiddens)\n        return output, state\n\n\n# 定义预测函数\ndef predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n                      char_to_idx):\n    state = None\n    output = [char_to_idx[prefix[0]]]  # output记录prefix加上预测的num_chars个字符\n    for t in range(num_chars + len(prefix) - 1):\n        X = torch.tensor([output[-1]], device=device).view(1, 1)\n        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(Y.argmax(dim=1).item())\n    return ''.join([idx_to_char[i] for i in output])","execution_count":4},{"metadata":{"id":"9227D56D455946B489B16F92BB55E7DB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"# 定义训练函数\ndef train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes):\n    loss = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    model.to(device)\n    for epoch in range(num_epochs):\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = d2l.data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\n        state = None\n        for X, Y in data_iter:\n            if state is not None:\n                # 使用detach函数从计算图分离隐藏状态\n                if isinstance (state, tuple): # LSTM, state:(h, c)  \n                    state[0].detach_()\n                    state[1].detach_()\n                else: \n                    state.detach_()\n            (output, state) = model(X, state) # output.shape: (num_steps * batch_size, vocab_size)\n            y = torch.flatten(Y.T)\n            l = loss(output, y.long())\n            \n            optimizer.zero_grad()\n            l.backward()\n            grad_clipping(model.parameters(), clipping_theta, device)\n            optimizer.step()\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n        \n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn_pytorch(\n                    prefix, pred_len, model, vocab_size, device, idx_to_char,\n                    char_to_idx))","execution_count":null},{"metadata":{"id":"4CD4E974D0354D2EBCABF047076C6AD1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"# 训练模型\nnum_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\ntrain_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                            corpus_indices, idx_to_char, char_to_idx,\n                            num_epochs, num_steps, lr, clipping_theta,\n                            batch_size, pred_period, pred_len, prefixes)","execution_count":null},{"metadata":{"id":"0C9661AF1E01423988A1051313B3A9AB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"#","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}