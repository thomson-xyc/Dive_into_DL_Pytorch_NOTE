{"cells":[{"metadata":{"id":"8501FDA46A784333ACD37781796797D5","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 个人笔记——softmax回归"},{"metadata":{"id":"AC95DA2155604CD999F4FCBF1DC2BC64","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"softmax与线性回归相似，也是单层神经网络，只是它有多个输出值，因此常用来处理分类问题\n![Image Name](https://cdn.kesci.com/upload/image/q5mmhujmua.png?imageView2/0/w/960/h/960)\n根据上图，最终的输出值可表示为：\n![Image Name](https://cdn.kesci.com/upload/image/q5mmlt8rkj.PNG?imageView2/0/w/960/h/960)\n更进一步，为：\n![Image Name](https://cdn.kesci.com/upload/image/q5mmmib52x.PNG?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"F84400E42D984683AC36C7957BB42EC1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 获取图像数据集\n通过一个图片分类的问题学习用pytorch实现softmax回归"},{"metadata":{"id":"802F81ECBF0A49319E566589E43A46EC","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"1.3.0\n0.4.1a0+d94043a\n","name":"stdout"}],"source":"# 获取数据集\n%matplotlib inline\nfrom IPython import display\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.nn import init\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport sys\nimport numpy as np\nsys.path.append(\"/home/kesci/input\")\nimport d2lzh1981 as d2l\n\nprint(torch.__version__)\nprint(torchvision.__version__)","execution_count":1},{"metadata":{"id":"E481A52E6FAD4EEC8731184403DAC3B3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"26427392it [00:07, 3537223.63it/s]                              \n","name":"stderr"},{"output_type":"stream","text":"Extracting /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw\n","name":"stdout"},{"output_type":"stream","text":"\r0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"32768it [00:01, 22919.62it/s]                           \n0it [00:00, ?it/s]","name":"stderr"},{"output_type":"stream","text":"Extracting /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":" 99%|█████████▉| 4390912/4422102 [00:20<00:00, 366238.47it/s]\n0it [00:00, ?it/s]\u001b[A","name":"stderr"},{"output_type":"stream","text":"Extracting /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"stream","text":"\n  0%|          | 0/5148 [00:00<?, ?it/s]\u001b[A\n8192it [00:00, 10479.56it/s]            \u001b[A","name":"stderr"},{"output_type":"stream","text":"Extracting /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /home/kesci/Datasets/FashionMNIST/FashionMNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"\r4423680it [00:40, 366238.47it/s]                             ","name":"stderr"}],"source":"# 获取数据集\nmnist_train = torchvision.datasets.FashionMNIST(root='/home/kesci/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())\nmnist_test = torchvision.datasets.FashionMNIST(root='/home/kesci/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())","execution_count":2},{"metadata":{"id":"FD59DC70F4A640538428FBAEF056C605","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"<class 'torchvision.datasets.mnist.FashionMNIST'>\n60000 10000\ntorch.Size([1, 28, 28]) 9\n","name":"stdout"},{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 864x864 with 10 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/FD59DC70F4A640538428FBAEF056C605/q5mwi85z48.svg\">"},"transient":{}}],"source":"# 查看数据集大小\nprint(type(mnist_train))\nprint(len(mnist_train), len(mnist_test))\n# 数据集操作\nfeature, label = mnist_train[0]  # 通过下标访问样本\nprint(feature.shape, label)\n# 封装函数将数值标签转成相应文本标签\ndef get_fashion_mnist_labels(labels):\n    text_labels = ['t-shirt','trouser','pullover','dress',\n                   'coat','sandal','shirt','sneaker','bag','ankle boot']\n    return [text_labels[int(i)] for i in labels]\n# 定义函数，功能：在一行中画出多张图像和对应标签\ndef show_fashion_mnist(images, labels):\n    d2l.use_svg_display()\n    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n    for f, img, lbl in zip(figs, images, labels):\n        f.imshow(img.view((28, 28)).numpy())\n        f.set_title(lbl)\n        f.axes.get_xaxis().set_visible(False)\n        f.axes.get_yaxis().set_visible(False)\n    plt.show()\n\n# 查看训练数据集前9个样本图像和文本标签\nX, y = [], []\nfor i in range(10):\n    X.append(mnist_train[i][0])\n    y.append(mnist_train[i][1])\nshow_fashion_mnist(X, get_fashion_mnist_labels(y))","execution_count":3},{"metadata":{"id":"99B9D0F2153045C296FC0C10FC190261","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"笔记：实践中可以通过多进程加速数据的读取，pytorch有相应的功能"},{"metadata":{"id":"956D2774D73D4B888F377DE99C73E47F","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"4.745744466781616 sec\n","name":"stdout"}],"source":"# 多进程读取数据\n# 读取数据\nbatch_size = 256\nif sys.platform.startswith('win'):\n    num_workers = 0  # 不用额外进程加速读取数据\nelse:\n    num_workers = 4\n# num_workers = 4\ntrain_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntest_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n# 读取一遍训练数据所需时间\nstart = time.time()\nfor X, y in train_iter:\n    continue\nprint('{} sec'.format(time.time() - start))","execution_count":4},{"metadata":{"id":"088BDBFA6C30480C89AF11086D74BE74","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## pytorch实现softmax回归"},{"metadata":{"id":"9E93987108EB49A08C95636C687984F0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 获取数据\nbatch_size = 256\ntrain_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n# 初始化参数\nnum_inputs = 784\nnum_outputs = 10\n\nclass LinearNet(nn.Module):\n    def __init__(self, num_inputs, num_outputs):\n        super(LinearNet, self).__init__()\n        self.linear = nn.Linear(num_inputs, num_outputs)\n    def forward(self, x): # x 的形状: (batch, 1, 28, 28)\n        y = self.linear(x.view(x.shape[0], -1))\n        return y\nnet = LinearNet(num_inputs, num_outputs)\n# 定义函数记录转换功能\nclass FlattenLayer(nn.Module):\n    def __init__(self):\n        super(FlattenLayer, self).__init__()\n    def forward(self, x): # x 的形状: (batch, *, *, ...)\n        return x.view(x.shape[0], -1)","execution_count":5},{"metadata":{"id":"821D88E10766427A80566E073DBE1194","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"},"transient":{},"execution_count":6}],"source":"# d定义模型并初始化\nfrom collections import OrderedDict\nnet = nn.Sequential(\n        # FlattenLayer(),\n        # LinearNet(num_inputs, num_outputs) \n        OrderedDict([\n           ('flatten', FlattenLayer()),\n           ('linear', nn.Linear(num_inputs, num_outputs))]))\ninit.normal_(net.linear.weight, mean=0, std=0.01)\ninit.constant_(net.linear.bias, val=0)","execution_count":6},{"metadata":{"id":"05FAAD60A56D45E5B7DE3D298E1190AE","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"使用交叉熵损失函数\n笔记：这里处理的是分类问题，只要选出预测值中最大者即可得到结果，因此无需像线性回归那样使用均方误差，使用均方误差对于分类模型可能太过严格，这里使用交叉熵损失函数即可，只要分类正确就行"},{"metadata":{"id":"A7F1F8AA7F4E44ECAAAB91D232523F2A","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 损失函数；\n# 为避免softmax运算和交叉熵运算分开定义造成的数值不稳定，\n# 调用同时定义的损失函数\nloss = nn.CrossEntropyLoss()\n\n# 优化算法\noptimizer = torch.optim.SGD(net.parameters(), lr=0.1)","execution_count":7},{"metadata":{"id":"5124C1DEA00A4E7882E32DA7F94BF237","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"epoch 1, loss 0.0031, train acc 0.750, test acc 0.760\nepoch 2, loss 0.0022, train acc 0.813, test acc 0.808\nepoch 3, loss 0.0021, train acc 0.825, test acc 0.818\nepoch 4, loss 0.0020, train acc 0.832, test acc 0.805\nepoch 5, loss 0.0019, train acc 0.836, test acc 0.822\n","name":"stdout"}],"source":"# 训练算法\nnum_epochs = 5 \nd2l.train_ch3(net, train_iter, test_iter, loss, \n    num_epochs, batch_size, None, None, optimizer)","execution_count":8},{"metadata":{"id":"F7660AB1D6764976820593B97F57E8A4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 864x864 with 9 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/F7660AB1D6764976820593B97F57E8A4/q5mwl7w0j5.svg\">"},"transient":{}}],"source":"# 模型预测\nX, y = iter(test_iter).next()\n\ntrue_labels = d2l.get_fashion_mnist_labels(y.numpy())\npred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())\ntitles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n\nd2l.show_fashion_mnist(X[0:9], titles[0:9])","execution_count":9},{"metadata":{"id":"886FC8284A824678BC6501D0D2D05380","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"线性回归：https://www.kesci.com/org/boyuai/project/share/4b72c6515eb2ec7f\n多层感知机：https://www.kesci.com/org/boyuai/project/share/fe09890d6a297909"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}