{"cells":[{"metadata":{"cell_type":"code","id":"79480DC5699D4F518345FD2F9E8129A2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 循环神经网络进阶\n## 门控循环单元(GRU)\nRNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）\n⻔控循环神经⽹络：捕捉时间序列中时间步距离较⼤的依赖关系\n![Image Name](https://cdn.kesci.com/upload/image/q5w04w3ui8.PNG?imageView2/0/w/960/h/960)\n下面是用pytorch实现："},{"metadata":{"id":"41B321D8E55A4581A642739D4761D7ED","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 载入数据集\nimport os\nos.listdir('/home/kesci/input')\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport sys\nsys.path.append(\"../input/\")\nimport d2l_jay9460 as d2l\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()","execution_count":2},{"metadata":{"id":"15D48ACECD7747BE98403DB57DEBEACB","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"# 初始化参数\nnum_hiddens=256\nnum_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\npred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n\nlr = 1e-2 # 注意调整学习率\ngru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)\nmodel = d2l.RNNModel(gru_layer, vocab_size).to(device)\nd2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes)","execution_count":null},{"metadata":{"id":"677E5C22E15A4EB288B2D842CD4C0D65","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 长短期记忆LSTM（long short-term memory）\n遗忘门:控制上一时间步的记忆细胞 输入门:控制当前时间步的输入\n输出门:控制从记忆细胞到隐藏状态\n记忆细胞：⼀种特殊的隐藏状态的信息的流动\n![Image Name](https://cdn.kesci.com/upload/image/q5w0k3c20j.PNG?imageView2/0/w/960/h/960)\npytorch实现如下："},{"metadata":{"id":"304740DCE5D544758A0F627C5CCA6AB2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"# pytorch实现\nnum_hiddens=256\nnum_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\npred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n\nlr = 1e-2 # 注意调整学习率\nlstm_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens)\nmodel = d2l.RNNModel(lstm_layer, vocab_size)\nd2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes)","execution_count":null},{"metadata":{"id":"0FB0883D6D8B40588367D7DD5F44D9C3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 深度循环神经网络\n![Image Name](https://cdn.kesci.com/upload/image/q5w0ovqilj.PNG?imageView2/0/w/960/h/960)\npytorch实现："},{"metadata":{"id":"FA4BC2D0E02F45188F1FE6005D227F1E","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"num_hiddens=256\nnum_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2\npred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n\nlr = 1e-2 # 注意调整学习率\n\ngru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=2)\nmodel = d2l.RNNModel(gru_layer, vocab_size).to(device)\nd2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes)\n\n#                                 \ngru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=6)\nmodel = d2l.RNNModel(gru_layer, vocab_size).to(device)\nd2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes)","execution_count":null},{"metadata":{"id":"B19FBA8BA03B48B7AB212A7A6AA36A54","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 双向循环神经网络\n![Image Name](https://cdn.kesci.com/upload/image/q5w0t38zpn.PNG?imageView2/0/w/960/h/960)\npytorch实现："},{"metadata":{"id":"5F7825ACBFD04B4FBA6A302DF8481A3D","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"num_hiddens=128\nnum_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e-2, 1e-2\npred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n\nlr = 1e-2 # 注意调整学习率\n\ngru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens,bidirectional=True)\nmodel = d2l.RNNModel(gru_layer, vocab_size).to(device)\nd2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes)","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}